# Pyspark-Neo4j
 PART A

•The aim is to analyse the performance of the spark-architecture based on scalability.
•The data sets selected for this task is NYC taxi data sets which contains the taxi trips details in New York city.
•The time taken for the execution of data sets whose size vary in different scale(3M­l 30M) is evaluated for understanding the system's 
 scalability.

PART B

•The aim is to choose the zones having hub like characteristics for minimizing the cost under this conditions.
a.	maximum 20 zone spread across the city and maximum trip served
b.	Considers operating outside Manhattan city.
•The different algorithm used for finding the centrality and detection of community is analysed in this assignment.
•The data set contains aggregate statistics of taxi trips undertaken in 2021.

For Further Information refer 
[Click here](https://github.com/raj-akhil/Pyspark-Neo4j/blob/main/c1040918-presentation-video.pdf)
